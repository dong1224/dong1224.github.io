# cpu和内存虚拟化（二）

## 1. 为什么需要 CPU 虚拟化

X86 操作系统是设计在直接运行在裸硬件设备上的，
因此它们自动认为它们完全占有计算机硬件。x86 架构提供四个特权级别给操作系统和应用程序来访问硬件。 
Ring 是指 CPU 的运行级别，Ring 0是最高级别，Ring1次之，Ring2更次之…… 就 Linux+x86 来说， 
- 操作系统（内核）需要直接访问硬件和内存，因此它的代码需要运行在最高运行级别  Ring0上，这样它可以使用特权指令，
控制中断、修改页表、访问设备等等。 
- 应用程序的代码运行在最低运行级别上ring3上，不能做受控操作。
如果要做，比如要访问磁盘，写文件，那就要通过执行系统调用（函数），
执行系统调用的时候，CPU的运行级别会发生从ring3到ring0的切换，并跳转到系统调用对应的内核代码位置执行，
这样内核就为你完成了设备访问，完成之后再从ring0返回ring3。这个过程也称作用户态和内核态的切换。
[1.1](https://images0.cnblogs.com/blog2015/697113/201506/011405050662145.jpg)

那么，虚拟化在这里就遇到了一个难题，因为宿主操作系统是工作在 ring0 的，
客户操作系统就不能也在 ring0 了，但是它不知道这一点，以前执行什么指令，
现在还是执行什么指令，但是没有执行权限是会出错的。所以这时候虚拟机管理程序（VMM）需要避免这件事情发生。
 虚机怎么通过 VMM 实现 Guest CPU 对硬件的访问，根据其原理不同有三种实现技术：
1. 全虚拟化
2. 半虚拟化
3. 硬件辅助的虚拟化 

### 基于二进制翻译的全虚拟化（Full Virtualization with Binary Translation）

[1.2](https://images0.cnblogs.com/blog2015/697113/201506/011406053161018.jpg)

客户操作系统运行在 Ring 1，它在执行特权指令时，会触发异常（CPU的机制，没权限的指令会触发异常），
然后 VMM 捕获这个异常，在异常里面做翻译，模拟，最后返回到客户操作系统内，
客户操作系统认为自己的特权指令工作正常，继续运行。但是这个性能损耗，就非常的大，
简单的一条指令，执行完，了事，现在却要通过复杂的异常处理过程。

异常 “捕获（trap）-翻译（handle）-模拟（emulate）” 过程：
[1.3](https://images0.cnblogs.com/blog2015/697113/201506/011407133943983.jpg)

### 1.2. 超虚拟化（或者半虚拟化/操作系统辅助虚拟化 Paravirtualization） 

半虚拟化的思想就是，修改操作系统内核，替换掉不能虚拟化的指令，
通过超级调用（hypercall）直接和底层的虚拟化层hypervisor来通讯，
hypervisor 同时也提供了超级调用接口来满足其他关键内核操作，比如内存管理、中断和时间保持。
这种做法省去了全虚拟化中的捕获和模拟，大大提高了效率。所以像XEN这种半虚拟化技术，
客户机操作系统都是有一个专门的定制内核版本，和x86、mips、arm这些内核版本等价。
这样以来，就不会有捕获异常、翻译、模拟的过程了，性能损耗非常低。这就是XEN这种半虚拟化架构的优势。
这也是为什么XEN只支持虚拟化Linux，无法虚拟化windows原因，微软不改代码啊。

### 1.3. 硬件辅助的全虚拟化 

2005年后，CPU厂商Intel 和 AMD 开始支持虚拟化了。 Intel 引入了 Intel-VT （Virtualization Technology）技术。 
这种 CPU，有 VMX root operation 和 VMX non-root operation两种模式，两种模式都支持Ring 0 ~ Ring 3 共 4 个运行级别。
这样，VMM 可以运行在 VMX root operation模式下，客户 OS 运行在VMX non-root operation模式下。

[1.4](https://images0.cnblogs.com/blog2015/697113/201506/011409366449146.jpg)

而且两种操作模式可以互相转换。运行在 VMX root operation 模式下的 VMM 通过显式调用 VMLAUNCH 或 VMRESUME 指令
切换到 VMX non-root operation 模式，硬件自动加载 Guest OS 的上下文，于是 Guest OS 获得运行，这种转换称为 VM entry。
Guest OS 运行过程中遇到需要 VMM 处理的事件，例如外部中断或缺页异常，
或者主动调用 VMCALL 指令调用 VMM 的服务的时候（与系统调用类似），硬件自动挂起 Guest OS，
切换到 VMX root operation 模式，恢复 VMM 的运行，这种转换称为 VM exit。VMX root operation 模式下软件的行为
与在没有 VT-x 技术的处理器上的行为基本一致；而VMX non-root operation 模式则有很大不同，
最主要的区别是此时运行某些指令或遇到某些事件时，发生 VM exit。

也就说，硬件这层就做了些区分，这样全虚拟化下，那些靠“捕获异常-翻译-模拟”的实现就不需要了。
而且CPU厂商，支持虚拟化的力度越来越大，靠硬件辅助的全虚拟化技术的性能逐渐逼近半虚拟化，
再加上全虚拟化不需要修改客户操作系统这一优势，全虚拟化技术应该是未来的发展趋势。

## 2. KVM CPU 虚拟化

KVM 是基于CPU 辅助的全虚拟化方案，它需要CPU虚拟化特性的支持。

### 2.1. CPU 物理特性

这个命令查看主机上的CPU 物理情况：

	[s1@rh65 ~]$ numactl --hardware
	available: 2 nodes (0-1) //2颗CPU
	node 0 cpus: 0 1 2 3 4 5 12 13 14 15 16 17 //这颗 CPU 有8个内核
	node 0 size: 12276 MB
	node 0 free: 7060 MB
	node 1 cpus: 6 7 8 9 10 11 18 19 20 21 22 23
	node 1 size: 8192 MB
	node 1 free: 6773 MB
	node distances:
	node   0   1 
	  0:  10  21 
	  1:  21  10
	  
要支持 KVM， Intel CPU 的 vmx 或者 AMD CPU 的 svm 扩展必须生效了：

	[root@rh65 s1]# egrep "(vmx|svm)" /proc/cpuinfo
	flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 popcnt aes lahf_lm arat epb dts tpr_shadow vnmi flexpriority ept vpid
	
### 2.2 多 CPU 服务器架构：SMP，NMP，NUMA

从系统架构来看，目前的商用服务器大体可以分为三类：

- 多处理器结构 (SMP ： Symmetric Multi-Processor)：所有的CPU共享全部资源，如总线，内存和I/O系统等，
操作系统或管理数据库的复本只有一个，这种系统有一个最大的特点就是共享所有资源。
多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。SMP 服务器的主要问题，
那就是它的扩展能力非常有限。实验证明， SMP 服务器 CPU 利用率最好的情况是 2 至 4 个 CPU 。
- 海量并行处理结构 (MPP ： Massive Parallel Processing) ：NUMA 服务器的基本特征是具有多个 CPU 模块，
每个 CPU 模块由多个 CPU( 如 4 个 ) 组成，并且具有独立的本地内存、 I/O 槽口等。在一个物理服务器内可以支持上百个 CPU 。
但 NUMA 技术同样有一定缺陷，由于访问远地内存的延时远远超过本地内存，因此当 CPU 数量增加时，系统性能无法线性增加。
- MPP 模式则是一种分布式存储器模式，能够将更多的处理器纳入一个系统的存储器。一个分布式存储器模式具有多个节点，
每个节点都有自己的存储器，可以配置为SMP模式，也可以配置为非SMP模式。单个的节点相互连接起来就形成了一个总系统。
MPP可以近似理解成一个SMP的横向扩展集群，MPP一般要依靠软件实现。
- 非一致存储访问结构 (NUMA ： Non-Uniform Memory Access)：它由多个 SMP 服务器通过一定的节点互联网络进行连接，
协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。
其基本特征是由多个 SMP 服务器 ( 每个 SMP 服务器称节点 ) 通过节点互联网络连接而成，
每个节点只访问自己的本地资源 ( 内存、存储等 ) ，是一种完全无共享 (Share Nothing) 结构。

查看你的服务器的 CPU 架构：

	[root@rh65 s1]# uname -a
	Linux rh65 2.6.32-431.el6.x86_64 #1 SMP Sun Nov 10 22:19:54 EST 2013 x86_64 x86_64 x86_64 GNU/Linux #这服务器是 SMP 架构 

## 2.2 KVM CPU 虚拟化

### 2.2.1 KVM 虚机的创建过程